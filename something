// import {ChatOpenAI} from "langchain/chat_models/openai";
// import {DynamicStructuredTool} from "langchain/tools";
// import {z} from 'zod'
// const llm = new ChatOpenAI({
//   temperature: 0.7, // Creativity level
//   modelName: "gpt-3.5-turbo" // or "gpt-4"
// });

// const getInfo = new DynamicStructuredTool({
//   name:"gSort",
//   description:'garbage sort',
//   schema:z.object({
//     item: z.string(),
//     city: z.string()
//   }),
//   func: async ({ item, city }) => {
//     // Logic or DB lookup
//     if (item.toLowerCase().includes("plastic") && city.toLowerCase() === "delhi") {
//       return "Blue bin";
//     } else {
//       return "General waste";
//     }
//   }
// });
// const executor = await initializeAgentExecutorWithOptions(
//   [getInfo],
//   llm,
//   {
//     agentType: "zero-shot-react-description", // agent logic style
//     verbose: true, // debug info
//     maxIterations: 3
//   }
// )

// const result = await executor.run("How to dispose plastic bottle in Delhi?");
// console.log(result);

const handleMic=async()=>{
    const stream = await navigator.mediaDevices.getUserMedia({audio:true}); //MIC PERMISSION FROM BROWSER
    const mediaRecorder = new MediaRecorder(stream);
    let chunks = [] //AUDIO RECORDED TO BE COLLECTED IN CHUNKS
    mediaRecorder.ondataavailable = (e) => {
      chunks.push(e.data)
    }
    mediaRecorder.onstop = () => { //ONCES STOPPED COMBINE IT IN 1 BLOB
      const blob = new Blob(chunks, { type: "audio/wav" })
      console.log("Recorded Blob:", blob)
      const formData = new FormData(); //APPEND TO FORMDATA AND USE IT AS PER USE
      formData.append("file",blob,"farmer_audio.wav")
    }
    mediaRecorder.start();
    -------
    mediaRecorder.stop();
}
//BLOBE IS WARPPED INTO FORMDATA AND SENT TO BACKEND
//FETCH IT AND UPLOAD IT TEMPERARILY IN UPLOAD FOLDER
//THEN WHISPER IS CALLED(SPAWN ALLOWS USING IT ALONG WITH OTHER LIBRARIES)
//GENERATES .TXT FILE
//TRANSCRIBED TEXT SENT TO MONGO